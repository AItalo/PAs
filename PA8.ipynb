{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 310](https://github.com/GonzagaCPSC310) Data Mining\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "# PA8 Association Rule Mining (100 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Perform association rule mining using the apriori algorithm\n",
    "* Evaluate rules using rule interestingness measures\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Use Python for data analysis\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining HW7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repositories to track code changes and submit your assignment. Open this PA8 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/7jnFHuNa\n",
    "\n",
    "Your repo, for example, will be named GonzagaCPSC310/pa8-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up. We will grade your most recent commit, even if that commit is after the due date (your work will be marked late if this is the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Requirements\n",
    "Write a program (`pa8.py`) that implements the apriori association rule mining algorithm. You will use your apriori algorithm it to identify association rules in the titanic and mushroom agaricus-lepiota datasets (see below for a description of the latter). Download the titanic.txt dataset and the agaricus-lepiota.txt dataset from https://github.com/GonzagaCPSC310/PAs/tree/master/files\n",
    "\n",
    "For this assignment you will need to perform the following steps and turn in your source code and a log of any assumptions and/or issues you had in doing the steps. Your log needs to be written separately from your .py file and may be written in a .txt or a .md (markdown) file.\n",
    "\n",
    "Note: as you write solutions for the following steps, I highly encourage you to design functions that are generic and re-usable for future programming assignments and data mining tasks.\n",
    "\n",
    "Note: we are learning data mining from scratch! The only libraries you should need to use for this assignment include numpy (sparingly), csv (if you'd like to use it for file I/O), and tabulate (if you'd like to use it for pretty printing). This means no pandas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Implement the apriori algorithm from class. Your apriori implementation should return a set of rules with their corresponding support, confidence, and lift \"interestingness\" measures. Your algorithm should also be parameterized to accept different min-support (`minsup`) and confidence (`minconf`) values. Your program should \"pretty print\" the discovered rules with their corresponding support, confidence, and lift values (see the example pretty print below for the titantic dataset).\n",
    "\n",
    "Run your apriori algorithm over the example datasets from class. Only after you are confident that your apriori algorithm is working correctly, move on to the next step. For convenience, I've provided the datasets as Python lists below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. interview dataset\n",
    "header = [\"level\", \"lang\", \"tweets\", \"phd\", \"interviewed_well\"]\n",
    "table = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\", \"False\"]\n",
    "    ]\n",
    "\n",
    "# 2. toy market basket analysis dataset\n",
    "I = [\"b\", \"c\", \"e\", \"m\", \"s\"]\n",
    "transactions = [\n",
    "    [\"b\", \"c\", \"m\"],\n",
    "    [\"b\", \"c\", \"e\", \"m\", \"s\"],\n",
    "    [\"b\"],\n",
    "    [\"c\", \"e\", \"s\"],\n",
    "    [\"c\"],\n",
    "    [\"b\", \"c\", \"s\"],\n",
    "    [\"c\", \"e\", \"s\"],\n",
    "    [\"c\", \"e\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Run your apriori algorithm over the titanic dataset. Run and analyze your results using different min support and confidence values. Your program should \"pretty print\" the discovered rules with their corresponding support, confidence, and lift values. For example:\n",
    "\n",
    "```\n",
    "association rule support confidence lift\n",
    "1 Class=2nd => Age=Adult ??? ??? ???\n",
    "2 Class=3rd => Age=Adult ??? ??? ???\n",
    "3 Survived=Yes => Age=Adult ??? ??? ???\n",
    "4 Class=Crew => Gender=Male ??? ??? ???\n",
    "...\n",
    "```\n",
    "\n",
    "Write a short description of the rules your implementation found focusing on (i) whether they make sense to you, and (i) how they compare (if at all) to your classification results from PA5 and PA6. Also briefly describe how the different values of min support and confidence changed the rules generated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Run your apriori algorithm over the mushroom dataset. The \"preprocessed\" agaricus-lepiota.txt dataset represents information about different types of mushrooms and whether they are edible or poisonous. This dataset has 23 nominal attributes (by order in the following table):\n",
    "\n",
    "1. The class label edible=e, poisonous=p\n",
    "2. cap-shape bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s\n",
    "3. cap-surface fibrous=f, grooves=g, scaly=y, smooth=s\n",
    "4. cap-color brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "5. bruises? bruises=t, no=f\n",
    "6. odor almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s\n",
    "7. gill-attachment attached=a, descending=d, free=f, notched=n\n",
    "8. gill-spacing close=c, crowded=w, distant=d\n",
    "9. gill-size broad=b, narrow=n\n",
    "10. gill-color black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "11. stalk-shape enlarging=e, tapering=t\n",
    "12. stalk-root bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r\n",
    "13. stalk-surface-above-ring fibrous=f,scaly=y,silky=k,smooth=s\n",
    "14. stalk-surface-below-ring fibrous=f,scaly=y,silky=k,smooth=s\n",
    "15. stalk-color-above-ring brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "16. stalk-color-below-ring brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "17. veil-type partial=p, universal=u\n",
    "18. veil-color brown=n, orange=o, white=w, yellow=y\n",
    "19. ring-number none=n, one=o, two=t\n",
    "20. ring-type cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z\n",
    "21. spore-print-color black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y\n",
    "22. population abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y\n",
    "23. habitat grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d\n",
    "\n",
    "For this dataset, you will want to do feature selection (because of the number of attributes). Try different numbers of features to remove and report on the effect of the rules generated and the performance in terms of the time it takes for your implementation to find the rules.\n",
    "\n",
    "Run and analyze your results using different min support and confidence values. Your program should \"pretty print\" the discovered rules with their corresponding support, confidence, and lift values.\n",
    "\n",
    "Write a short description of the rules your implementation found focusing on whether they make sense to you. Also briefly describe how the different values of min support and confidence changed the rules generated. \n",
    "\n",
    "For convenience, I've provided a list representing the dataset header if you'd like to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises?\", \"odor\", \"gill-attachment\", \\\n",
    "          \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \\\n",
    "          \"stalk-surface-below-ring\", \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \\\n",
    "          \"veil-color\", \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Use Github classroom to submit your assignment via a Github repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this. You must commit your solution by the due date and time.\n",
    "1. Your repo should contain only your .py file(s), your input .csv/.txt file(s), and your log file (.txt or .md) file(s). Double check that this is the case by cloning (or downloading a zip) your submission repo and running your code from command line like we will when we grade your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 100 points. Your assignment will be evaluated based on a successful compilation from command line (using the Anaconda Python Distribution v3.7) and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 50 pts for correct step 1\n",
    "* 20 pts for correct step 2\n",
    "* 20 pts for correct step 3\n",
    "* 10 pts for adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC310/PAs/blob/master/Coding%20Standard.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
