{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 310](https://github.com/GonzagaCPSC310) Data Mining\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "# BONUS PA7 Ensemble Learning (30 BONUS pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Implement a random forest ensemble learner\n",
    "* Build a random forest using bagging\n",
    "* Introduce random attribute subsets for building a decision tree\n",
    "* Tune ensemble learning parameters\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Represent a tree in Python as a nested list\n",
    "* Implement a decision tree classifier using the TDIDT algorithm and entropy-based attribute selection\n",
    "* Evaluate classifiers using train/test sets\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining HW5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repositories to track code changes and submit your assignment. Open this PA7 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/rYB5L1R7 \n",
    "\n",
    "Your repo, for example, will be named GonzagaCPSC310/pa7-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up. We will grade your most recent commit, even if that commit is after the due date (your work will be marked late if this is the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Requirements\n",
    "Write a program (`pa7.py`) that builds a random forest classifier for the \"pre-processed\" automobile dataset (auto-data.txt) you created for PA1 (pick one method to deal with missing values for this assignment (e.g., eliminate rows with missing values, use means or medians, etc.)), the titanic dataset, and the Wisconsin dataset. Download the titanic.txt dataset and the wisconsin.dat dataset from https://github.com/GonzagaCPSC310/PAs/tree/master/files\n",
    "\n",
    "For this assignment you will need to perform the following steps and turn in your source code and a log of any assumptions and/or issues you had in doing the steps. Your log needs to be written separately from your .py file and may be written in a .txt or a .md (markdown) file.\n",
    "\n",
    "Note: as you write solutions for the following steps, I highly encourage you to design functions that are generic and re-usable for future programming assignments and data mining tasks.\n",
    "\n",
    "Note: we are learning data mining from scratch! The only libraries you should need to use for this assignment include numpy (sparingly), csv (if you'd like to use it for file I/O), and tabulate (if you'd like to use it for pretty printing). This means no pandas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Implement a basic random forest algorithm as follows:\n",
    "1. Generate a random stratified test set consisting of one third of the original data set, with the\n",
    "remaining two thirds of the instances forming the \"remainder set\".\n",
    "1. Generate $N$ \"random\" decision trees using bootstrapping (giving a training and validation\n",
    "set) over the remainder set. At each node, build your decision trees by randomly selecting\n",
    "F of the remaining attributes as candidates to partition on. This is the standard random\n",
    "forest approach discussed in class. Note that to build your decision trees you should still use\n",
    "entropy; however, you are selecting from only a (randomly chosen) subset of the available\n",
    "attributes.\n",
    "1. Select the $M$ most accurate of the $N$ decision trees using the corresponding validation sets.\n",
    "1. Use simple majority voting to predict classes using the $M$ decision trees over the test set.\n",
    "1. Give the accuracy of the random forest approach.\n",
    "\n",
    "Run your random forest algorithm over the \"interview\" dataset using $N$ = 20, $M$ = 7, and $F$ = 2 and print the predictive accuracy of the random forest. Only after you are confident that your random forest classifier is working correctly, move on to the next step. For convenience, I've provided the column names and dataset as Python lists below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"level\", \"lang\", \"tweets\", \"phd\", \"interviewed_well\"]\n",
    "table = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\", \"False\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: because we randomly select the remainder set, you will likely get a different predictive accuracy each time you run your program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Run your random forest algorithm over both the titanic and auto data sets using $N$ = 20, $M$ = 7, and $F$ = 2 and print both the predictive accuracy of the random forests and the corresponding confusion matrices. In addition, build a single \"normal\" decision tree from the remainder set and print its predictive accuracy and confusion matrix against the test set (from 1 above) for comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Run your random forest algorithm for each data set to see the variation of results for different values of the parameters $N$, $M$, and $F$. Note that for each setting of $N$, $M$, and $F$, you will need to run your program multiple times because of the randomly generated remainder set to get a sense of the settings (e.g., you might run each setting 5 times). You should try a wide range of values including large values for $N$. Print out the results (i.e., the values for $N$, $M$, and $F$, the accuracy, and the confusion matrices) that seem to give the best results for each dataset. As in step 2, output the accuracy of the corresponding single \"normal\" decision tree as well for comparison. Report on the settings you tried and the results you obtained in your log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Run your random forest algorithm over the \"preprocessed\" wisconsin.dat dataset, which contains cases from a study that was conducted at the University of Wisconsin Hospitals in Madison, Wisconsin, about patients who had undergone surgery for breast cancer. The task is to determine if the detected tumor is benign (2) or malignant (4). This dataset has 10 attributes (by order in the table):\n",
    "\n",
    "1. clump thickness interval value `[1,10]`\n",
    "2. cell size interval value `[1,10]`\n",
    "3. cell shape interval value `[1,10]`\n",
    "4. marginal adhesion interval value `[1,10]`\n",
    "5. epithelial size interval value `[1,10]`\n",
    "6. bare nuclei interval value `[1,10]`\n",
    "7. bland chromatin interval value `[1,10]`\n",
    "8. normal nucleoli interval value `[1,10]`\n",
    "9. mitoses interval value `[1,10]`\n",
    "10. tumor `2=benign, 4=malignant`\n",
    "\n",
    "As in step 3, report the values for $N$, $M$, and $F$ along with the accuracy and confusion matrix that\n",
    "gives the best results. Also output the accuracy for a single \"normal\" decision tree for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "Modify your random forest algorithm to use the \"track record\" weighted voting scheme discussed in class (instead of simple majority voting). Compare your results to those from Steps 2-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Use Github classroom to submit your assignment via a Github repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this. You must commit your solution by the due date and time.\n",
    "1. Your repo should contain only your .py file(s), your input .csv/.txt file(s), and your log file (.txt or .md) file(s). Double check that this is the case by cloning (or downloading a zip) your submission repo and running your code from command line like we will when we grade your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 30 BONUS points. Your assignment will be evaluated based on a successful compilation from command line (using the Anaconda Python Distribution v3.7) and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 8 pts for correct step 1\n",
    "* 5 pts for correct step 2\n",
    "* 5 pts for correct step 3\n",
    "* 5 pts for correct step 4\n",
    "* 5 pts for correct step 5\n",
    "* 2 pts for adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC310/PAs/blob/master/Coding%20Standard.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
