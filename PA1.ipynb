{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 310](https://github.com/GonzagaCPSC310) Data Mining\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "## PA1 Python for Data Analysis (75 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Identify and remove duplicates from a table\n",
    "* Combine tables together\n",
    "* Clean data\n",
    "* Compute simple summary statistics\n",
    "* Handle missing values\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Understand terms and concepts in Chapters 1 and 2 of Bramer\n",
    "* Run Python scripts from the command line\n",
    "* Use Python variables, operators, lists, functions, conditionals, loops, and file I/O\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repositories to track code changes and submit your assignment. Open this PA1 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/AqfR7uZX\n",
    "\n",
    "Your repo, for example, will be named GonzagaCPSC310/pa1-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up. We will grade your most recent commit, even if that commit is after the due date (your work will be marked late if this is the case).\n",
    "\n",
    "Note: Working with Github classroom does not involve any forking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Requirements\n",
    "Write a program (pa1.py) that performs data pre-processing tasks on an automobile dataset. Download the auto-mpg.txt and auto-prices.txt datasets from https://github.com/GonzagaCPSC310/PAs/tree/master/files. These datasets contain information about cars manufactured and sold in the 1970's.\n",
    "\n",
    "The attributes of auto-mpg.txt are: \n",
    "* mpg (miles per gallon)\n",
    "* cylinders\n",
    "* displacement\n",
    "* horsepower\n",
    "* weight\n",
    "* acceleration\n",
    "* model year\n",
    "* origin\n",
    "* car name\n",
    "\n",
    "The attributes of auto prices.txt are: \n",
    "* car name\n",
    "* model year\n",
    "* msrp (manufacturer's suggested retail price)\n",
    "\n",
    "For this assignment you will need to perform the following steps and hand in your source code, tests, and a description (i.e., log) of the process you used to \"clean\" the given data. Your log needs to be written separately from your .py file and may be written in a .txt or a .md (markdown) file.\n",
    "\n",
    "Note: as you write solutions for the following steps, I highly encourage you to design functions that are generic and re-usable for future programming assignments and data mining tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "In pa1.py write functions to count the number of instances in the dataset and to find any duplicates (i.e., instances with the same car name and model year). If duplicates do exist, determine how to resolve them and then modify the dataset (i.e., manually copy the dataset to a new file, resolve the duplicates, then rerun the script OR programmatically resolve duplicates and write the modified dataset to a file). Be sure to write down the duplicates you found (if any), how you resolved them, and why you resolved them the way you did in your log. After you complete this step, running your pa1.py program should print the following:\n",
    "```\n",
    "--------------------------------------------------\n",
    "auto-mpg-nodups.txt:\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "--------------------------------------------------\n",
    "auto-prices-nodups.txt:\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "```\n",
    "\n",
    "where ??? should list the number of instances in the two datasets, respectively\n",
    "\n",
    "## Step 2\n",
    "Add functions to pa1.py to combine the two datasets, write out the result to auto-data.txt, and count the number of instances (as in Step 1 above). The result of this step should print the following (where ??? should be replaced with the actual number of instances):\n",
    "\n",
    "```\n",
    "--------------------------------------------------\n",
    "auto-mpg-nodups.txt:\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "--------------------------------------------------\n",
    "auto-prices-nodups.txt:\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "--------------------------------------------------\n",
    "combined table (saved as auto-data.txt):\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "```\n",
    "\n",
    "The combined dataset should have 10 attributes such that the first 9 attributes are those from auto-mpg.txt and the last attribute is the corresponding msrp (price) from auto-prices.txt. The two datasets should be combined (i.e., joined) on car name and model year. To combine the two datasets, you should perform a \"full outer join\". That is, you should not disregard non-matches and instead include non-matches by padding the attributes with missing values (denoted as \"NA\"). As an example, while there isn't a price listed in auto-prices.txt for a 1970 amc rebel sst, auto-data.txt should include an instance:\n",
    "```\n",
    "16.0,8,304.0,150.0,3433,12.0,70,1,amc rebel sst,NA\n",
    "```\n",
    "\n",
    "As another example, while there isn't an instance in auto-mpg.txt for a 1971 Audi 100 LS, auto-data.txt should include an instance:\n",
    "```\n",
    "NA,NA,NA,NA,NA,NA,71,NA,audi 100 ls,3595\n",
    "```\n",
    "\n",
    "## Step 3\n",
    "Updated 1/29/19 for clarification:\n",
    "\n",
    "Resolve (i.e., clean up) the cases in auto-data.txt in which there are prices but no mpg data. To do this, you may need to manually edit your auto-mpg-nodups.txt and/or auto-prices-nodups.txt files to resolve the issues (e.g., in the case of a misspelling), which will require you to regenerate the auto-data.txt file. Be sure to copy these files and rename them appropriately, e.g. auto-mpg-clean.txt and/or auto-prices-clean.txt. Also, write down in your log how and why you resolved these cases the way you did.\n",
    "\n",
    "## Step 4\n",
    "Add functions to pa1.py to compute summary statistics for auto-data.txt. For each continuous attribute, compute the minimum, maximum, midpoint (half way between min and max), average, and median values. You can ignore the categorical attributes for now (we'll look at these further in PA2). The result of running your program after this step should be similar to the following. The tables below were generated using the [`tabulate`](https://pypi.org/project/tabulate/) module (which you can install at the command line with `conda install tabulate` OR `pip install tabulate`). Note that your summary values may be different than those below.\n",
    "\n",
    "```\n",
    "--------------------------------------------------\n",
    "auto-mpg-clean.txt:\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "--------------------------------------------------\n",
    "auto-prices-clean.txt:\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "--------------------------------------------------\n",
    "combined table (saved as auto-data.txt):\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "Summary Stats:\n",
    "============ ===== ===== ======= ====== ======\n",
    "attribute min max mid avg med\n",
    "============ ===== ===== ======= ====== ======\n",
    "mpg 9 43.1 26.1 21.1 20\n",
    "displacement 68 455 261.5 214.3 200\n",
    "...\n",
    "msrp 1798 21497 11647.5 4131 3824.5\n",
    "============ ===== ===== ======= ====== ======\n",
    "\n",
    "```\n",
    "\n",
    "## Step 5\n",
    "Write functions to perform three different techniques to resolve missing values, and for each compute the same summary statistics as in Step 4. Note that there should only be three columns in auto-data.txt that contain missing values.\n",
    "1. The first approach should be to remove all instances with missing values.\n",
    "2. The second approach should be to replace missing values with their corresponding attribute's average value.\n",
    "3. And the third approach should also replace missing values with average values but based on meaningful subsets of the data, e.g., based on the model year, origin, or some combination of attributes that makes the most sense to you.\n",
    "\n",
    "Be sure to document your decisions in your log. The result of running your program should include the summary statistics for each approach.\n",
    "\n",
    "```\n",
    "...\n",
    "--------------------------------------------------\n",
    "combined table (saved as auto-data.txt):\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "Summary Stats:\n",
    "============ ===== ===== ======= ====== =====\n",
    "attribute min max mid avg med\n",
    "============ ===== ===== ======= ====== =====\n",
    "mpg 11 43.1 27.1 20.8 19.4\n",
    "...\n",
    "============ ===== ===== ======= ====== =====\n",
    "--------------------------------------------------\n",
    "combined table (rows w/ missing values removed):\n",
    "--------------------------------------------------\n",
    "No. of instances: ???\n",
    "Duplicates: []\n",
    "Summary Stats:\n",
    "============ ===== ===== ======= ====== =====\n",
    "attribute min max mid avg med\n",
    "============ ===== ===== ======= ====== =====\n",
    "mpg 9 43.1 26.1 21.1 20.2\n",
    "...\n",
    "============ ===== ===== ======= ====== =====\n",
    "etc.\n",
    "```\n",
    "\n",
    "## Bonus (3 pts)\n",
    "Change your program so the names of the two input files will be passed in to your program via [command line arguments](https://docs.python.org/3/tutorial/stdlib.html#command-line-arguments). Use the names of these files to programmatically create subsequent file names. For example, running your program as follows: \n",
    "```\n",
    "python pa1.py auto-mpg.txt auto-prices.txt\n",
    "```\n",
    "\n",
    "would produce the same file names as listed in the specifications above. But if the names of the files are car-mpg.txt and car-prices.txt, then running your program as follows:\n",
    "```\n",
    "python pa1.py car-mpg.txt car-prices.txt\n",
    "```\n",
    "\n",
    "would produce file names such as car-mpg-nodupgs.txt, car-prices-nodups.txt, car-data.txt, car-mpg-clean.txt, etc. Essentially, you are not hard-coding filenames in your program but instead constructing them at runtime using the command line arguments.\n",
    "\n",
    "If incorrect command line arguments are given (e.g. missing one of them), print a string showing usage instructions. This helps the user know how to run your program!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Use Github classroom to submit your assignment via a Github repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this. You must commit your solution by the due date and time.\n",
    "1. Your repo should contain only your .py file(s), your input .csv file(s), and your log file (.txt or .md). Double check that this is the case by cloning (or downloading a zip) your submission repo and running your code from command line like we will when we grade your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 75 points + 3 points bonus. Your assignment will be evaluated based on a successful compilation from command line (using the Anaconda Python Distribution v3.7) and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 10 pts for correct step 1\n",
    "* 10 pts for correct step 2\n",
    "* 10 pts for correct step 3\n",
    "* 10 pts for correct step 4\n",
    "* 15 pts for correct step 5\n",
    "* 10 pts for quality and clarity of the write-up in the log file\n",
    "* 10 pts for adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC310/PAs/blob/master/Coding%20Standard.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
