{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 310](https://github.com/GonzagaCPSC310) Data Mining\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "# PA5 Naive Bayes (100 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Implement a Naive Bayes classifier\n",
    "* Calculate conditional probabilities using a Gaussian distribution\n",
    "* Implement a Random and Zero-R classifier\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Implement a $k$NN classifier\n",
    "* Evaluate classifiers using train/test sets\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining HW4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repositories to track code changes and submit your assignment. Open this PA5 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/VohZiPzY\n",
    "\n",
    "Your repo, for example, will be named GonzagaCPSC310/pa5-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up. We will grade your most recent commit, even if that commit is after the due date (your work will be marked late if this is the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Requirements\n",
    "Write a program (`pa5.py`) that builds a Naive Bayes classifier for the \"pre-processed\" automobile dataset (auto-data.txt) you created for PA1 (pick one method to deal with missing values for this assignment (e.g., eliminate rows with missing values, use means or medians, etc.)) and the titanic dataset. Download the titanic.txt and dataset from https://github.com/GonzagaCPSC310/PAs/tree/master/files\n",
    "\n",
    "For this assignment you will need to perform the following steps and turn in your source code and a log of any assumptions and/or issues you had in doing the steps. Your log needs to be written separately from your .py file and may be written in a .txt or a .md (markdown) file.\n",
    "\n",
    "Note: as you write solutions for the following steps, I highly encourage you to design functions that are generic and re-usable for future programming assignments and data mining tasks.\n",
    "\n",
    "Note: we are learning data mining from scratch! The only libraries you should need to use for this assignment include numpy (sparingly), csv (if you'd like to use it for file I/O), and tabulate (if you'd like to use it for pretty printing). This means no pandas..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Create a Naive Bayes classifier for the \"train\" dataset from section 3.3 in Bramer. Your classifier should predict the class values from the day, season, wind, and rain attributes. Check your prior probabilities and posterior probabilities with Figure 3.2 and check your classifier's posterior probabilities for each class for the test instance (weekday, winter, high, heavy, ????). Only after you are confident that your Naive Bayes classifier is working correctly, move on to the next step. For convenience, I've provided the column names and dataset as Python lists below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"day\", \"season\", \"wind\", \"rain\", \"class\"]\n",
    "table = [\n",
    "    [\"weekday\", \"spring\", \"none\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"high\", \"heavy\", \"late\"], \n",
    "    [\"saturday\", \"summer\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"autumn\", \"normal\", \"none\", \"very late\"],\n",
    "    [\"holiday\", \"summer\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"sunday\", \"summer\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"high\", \"heavy\", \"very late\"],\n",
    "    [\"weekday\", \"summer\", \"none\", \"slight\", \"on time\"],\n",
    "    [\"saturday\", \"spring\", \"high\", \"heavy\", \"cancelled\"],\n",
    "    [\"weekday\", \"summer\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"saturday\", \"winter\", \"normal\", \"none\", \"late\"],\n",
    "    [\"weekday\", \"summer\", \"high\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"winter\", \"normal\", \"heavy\", \"very late\"],\n",
    "    [\"saturday\", \"autumn\", \"high\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"autumn\", \"none\", \"heavy\", \"on time\"],\n",
    "    [\"holiday\", \"spring\", \"normal\", \"slight\", \"on time\"],\n",
    "    [\"weekday\", \"spring\", \"normal\", \"none\", \"on time\"],\n",
    "    [\"weekday\", \"spring\", \"normal\", \"slight\", \"on time\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Create a Naive Bayes classifier that predicts mpg values (and then maps these to the DOE classification/ranking (given in PA2)) from the cylinders, weight, and model year attributes. For this step, treat cylinders and model year as categorical values and use the following discretization (based on NHTSA vehicle sizes) to convert weight to a categorical attribute:\n",
    "\n",
    "|Ranking |Range|\n",
    "|-|-|\n",
    "|5 |$\\geq$ 3500\n",
    "|4 |3000-3499|\n",
    "|3 |2500-2999|\n",
    "|2 |2000-2499|\n",
    "|1 |$\\leq$ 1999|\n",
    "\n",
    "Test your classifier by repeating steps 2-5 from PA4 using your Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Create a Naive Bayes classifier as in Step 1, but leave weight as a continuous attribute and calculate\n",
    "its conditional probability using the Gaussian distribution function from class. As in Step 2, test your\n",
    "classifier by repeating steps 2-5 from PA4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Use Naive Bayes and $k$-nearest neighbor to create two different classifiers to predict survival from the titanic dataset (titanic.txt). Note that the first line of the dataset lists the name of each attribute:\n",
    "* class\n",
    "* age\n",
    "* sex\n",
    "* surivived\n",
    "\n",
    "Your classifiers should use class, age, and sex attributes to determine the survival value. Be sure to write down any assumptions you make in creating the classifiers. Evaluate the performance of your classifier using stratified k-fold cross validation (with k = 10) and generate confusion matrices for the two classifiers. As in PA4, report both accuracy and error rate for the two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "How well does Naive Bayes and $k$NN classify the titanic dataset? A common approach to evaluate the performance of a classifier is to compare its results to \"baseline\" classifiers on the same dataset. Two common baseline classifiers are:\n",
    "1. Random classifier: classifies an instance by randomly choosing a class label (class labels probabilities of being chosen are weighted based on their frequency in the training set)\n",
    "1. Zero-R: classifies an instance using \"zero rules\"... it always predicts the most common class label in the training set. For example, if 99% of the dataset is positive instances, it always predicts positive.\n",
    "\n",
    "Create a Random classifier and a Zero-R classifier to predict survival from the titanic dataset. Compare your results for all four classifiers (Naive Bayes, $k$NN, Random, Zero-R). Be sure to write down any insights you find in your log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Use Github classroom to submit your assignment via a Github repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this. You must commit your solution by the due date and time.\n",
    "1. Your repo should contain only your .py file(s), your input .csv/.txt file(s), and your log file (.txt or .md) file(s). Double check that this is the case by cloning (or downloading a zip) your submission repo and running your code from command line like we will when we grade your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 100 points. Your assignment will be evaluated based on a successful compilation from command line (using the Anaconda Python Distribution v3.7) and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 20 pts for correct step 1\n",
    "* 20 pts for correct step 2\n",
    "* 15 pts for correct step 3\n",
    "* 15 pts for correct step 4\n",
    "* 15 pts for correct step 5\n",
    "* 5 pts for quantity and quality of Github commit messages\n",
    "* 10 pts for adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC310/PAs/blob/master/Coding%20Standard.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
